Источник: https://www.practicalai.io/implementing-simple-classification-using-neural-network-in-ruby

## Реализация простейшей классификации с использованием нейросети на Ruby
03.07.2017 автор [Soren D](https://www.practicalai.io/implementing-simple-classification-using-neural-network-in-ruby)

В этой статье автор показывает, как решить простую проблему классификации с использованием нейронной сети. Мы будем использовать
ruby гем [ruby-fann](https://github.com/tangledpath/ruby-fann) для установки нейросети, тренировки и выполнения предсказаний
за несколько минут. Для реализации мы будем использовать данные о поступлении в школу, это тот же набор данных, который
мы использовали в [Решении задачи классификации с использованием логистической регрессии](./Implementing-Classification-using-Logistic-Regression-in-Ruby.md)
Так что мы сможем сравнить результаты и понять, что лучше для решения этой задачи - нейросеть или логистическая регрессия.

Полный код из этой статьи находится [тут]().

### Данные
Наши данные содержат три ряда для каждого примера - ряды содержат следующие данные:

Результат первого экзамена (от 0 до 100)
Результат второго экзамена (от 0 до 100)
Поступление (1 для поступления, 0 - если не поступил)
Для понимания, что мы можем делать прогнозы на основании этих данных, мы создали XY график.

![logistic regression plot](../assets/images/logistic-regression-example-04.png)

### Архитектура нейросети

Прежде чем начать реализацию нейросети мы должны определить архитектуру сети, которую хотим построить. Мы будем строить трёхслойную сеть, используя некоторые правила, автор рекомендует нам следующие слои:

**Входной слой**: 2 нейрона (результаты за 1-й и 2-й экзамены)<br>
**Скрытый слой**: 6 скрытых нейронов<br>
**Выходной слой**: 1 нейрон<br>

Так как вывод нейросети не бинарный, то мы будем использовать округление для результатов классификации: если вывод будет меньше 0.5 мы классифицируем как не поступление и если вывод больше или равен 0.5, то мы классифицируем его как поступление. Заметьте, что определение архитектуры нейросети не является точной научной дисциплиной. Позже мы можем захотеть варьировать количество нейронов в скрытом слое после того, как мы увидим изменения производительности сети.

### Установка нейросети в Ruby

Мы готовы к реализации нейросети на Ruby. Для начала установим гем [ruby-fann](https://github.com/tangledpath/ruby-fann). Ruby-fann - это гем, реализующий интерфейс к библиотеке FANN (Быстрая Искуственная Нейро Сеть). [FANN](http://leenissen.dk/) - это бесплатная библиотека с открытым исходным кодом, которая реализует многослойные искуственные нейросети, с поддержкой как полностью соединённых[*](../foot-notes/terminology.md#полносвязанная-нейросеть), так и слабо связанных[*](foot-notes/terminology.md#слабосвязанная-нейросеть) типов.

Для установки гема:

```bash
gem install ruby-fann
```

Далее создаём [руби-файл](../source/example-neural-network-classification/example.rb) и подключим библиотеки `ruby-fann` и `CSV`.

```ruby
require 'csv'
require 'ruby-fann'
```

Далее, загрузим данные из CSV файла в массив независимых переменных (результаты сдачи 1-го и 2-го экзаменов), называемый x_data, и второй массив зависимой переменной (результат поступил / не поступил), называемый y_data.

Результаты сдачи экзаменов представлены как значения с плавающей точкой, а значение "поступил / не поступил" представлено целым числом 1 или 0. Обратите внимание, что y_data представляет собой массив, в который мы добавляем массивы из одного элемента. Именно такая структура нужна потому, что FANN нуждается в таком формате для предоставления данных для выходных нейронов.

```ruby
x_data = []
y_data = []
# Загружаем данные из CSV файла в два массива. Первый - независимые переменные X и второй массив - переменные Y, зависящие от X.
CSV.foreach("../common-data/admission.csv", headers: false) do |row|
  x_data.push([row[0].to_f, row[1].to_f])
  y_data.push([row[2].to_i])
end
```

Перед тем, как установить и обучить нашу нейросеть нам нужно разделить данные на два набора - для обучения и проверки. Это поможет нам быть уверенными в том, что модель не переобучится на наших данных. Для примера, мы распределим данные так - 20% на тестирование и 80% - на обучение. Разделим данные:

```ruby
# Разделим данные на наборы для тестирования и обучения
test_size_percentange = 20.0 # 20.0% на тестирование
test_set_size = x_data.size * (test_size_percentange/100.0)
test_x_data = x_data[0 .. (test_set_size - 1)]
test_y_data = y_data[0 .. (test_set_size - 1)]
training_x_data = x_data[test_set_size .. x_data.size]
training_y_data = y_data[test_set_size .. y_data.size]
```

С нашими данными мы можем уставновить нащу модель для обучения. Ruby-fann загрузить данные для обучения в класс примерно так:

```ruby
# Установка модели для обучения
train = RubyFann::TrainData.new(inputs: training_x_data, desired_outputs: training_y_data)
```

Запомните, что желаемым результатом должен быть двумерный массив, даже если вы имеете всего один выходной нейрон. Это требование нейросетей с множеством выходных нейронов.

Далее мы можем установить модель нашей нейросети с архитектурой, выбранной ранее. Мы установим 2 входных нейрона, один слой с шестью нейронами и один выходной нейрон:

```ruby
# Установим модель и обучим её, используя данные для обучения
model = RubyFann::Standard.new(
  num_inputs: 2,
  hidden_neurons: [6],
  num_outputs: 1
)
```

С установленной моделью мы можем обучить её. Мы обучим модель за максимум 5000 итераций, и через каждые 500 итераций мы запросим у FANN значение ошибки. Мы позволим процессу прерваться, если значение ошибки снизится менее чем на 0.01.

```ruby
# 5000 итераций для обучения, 500 итераций между проверкой изменения ошибки
model.train_on_data(train, 5000, 500, 0.01)
```

Вывод ошибки в процессе обучения является великолепным инструментом диагностики. Ошибка должна снижаться в процессе обучения модели. Если ошибка не уменьшается, значит мы должны остановить обучение и переоценить архитектуру нейросети. Неверно выбранная архитектура может препятствовать созданию нейросети, способной найти решение для наших данных.

С обученной моделью мы можем начать делать прогнозы - в этом примере мы предскажем, поступит ли ученик, основываясь на данных о результатах двух экзаменов - 45 баллов за первый и 85 баллов за второй экзамент:

```ruby
# Предсказание простого класса (1 - поступил, 0 - не поступил)
prediction = model.run([45, 85])
# Округлим выход сделанного предсказания
puts "Алгоритм предсказал класс: #{prediction.map(&:round)}"
```

Запуск предсказания прост. Выполнив `model.run` с данными мы сделаем предсказание и округлим полученный результат.

Для определения точности нашей модели мы запустим предсказания для каждого элемента массива тестовых данных. После этого мы сравним полученный результат с результатом, взятым из тестовых данных:

```ruby
predicted = []
test_x_data.each do |params|
  predicted.push(model.run(params).map(&:round))
end
correct = predicted.collect.with_index { |e,i| (e == test_y_data[i]) ? 1 : 0 }.inject { |sum,e| sum+e }
puts "Точность: #{(correct / test_set_size * 100.0).round(2)}% - тестовый набор данных #{test_size_percentange}%"
```

Запустим скрипт в терминале:

```bash
$ ruby nn.rb
Max epochs     5000. Desired error: 0.0099999998.
Epochs            1. Current error: 0.2523627877. Bit fail 80.
Epochs          500. Current error: 0.0136228483. Bit fail 3.
Epochs         1000. Current error: 0.0124439569. Bit fail 3.
Epochs         1500. Current error: 0.0123059917. Bit fail 3.
Epochs         2000. Current error: 0.0110324342. Bit fail 2.
Epochs         2500. Current error: 0.0108939139. Bit fail 3.
Epochs         3000. Current error: 0.0111556053. Bit fail 3.
Epochs         3500. Current error: 0.0108516226. Bit fail 2.
Epochs         4000. Current error: 0.0109892655. Bit fail 3.
Epochs         4500. Current error: 0.0106163323. Bit fail 1.
Epochs         5000. Current error: 0.0105525032. Bit fail 1.
Алгоритм предсказал класс: [1]
Точность: 100.0% - тестовый набор данных 20.0%
```

Первые строки - это вывод FANN при обучении сети. Как вы видите, ошибка уменьшается в процессе обучения сети, это говорит о том, что мы выбрали верную архитектуру сети и обеспечили её правильными данными. Далее мы видим, что предсказан класс [1] для студента с результатами экзаменов 45 баллов за первый экзамен и 85 баллов за второй экзамен. Глядя на исходный график, это кажется правдоподобным.

После, мы видим, что точность нашей нейросети на наших тестовых данных - 100%. Это намного лучше, чем алгоритм логистической регрессии, который давал точность 95% для этих же самых данных. Это показывает, что нейросеть лучше справляется с решением данной проблемы, чем [модель логистической регрессии](./Implementing-Classification-using-Logistic-Regression-in-Ruby.md), которую мы создавали ранее.

Первоисточник статьи и исходный код тут: https://github.com/daugaard/example-neural-network.
