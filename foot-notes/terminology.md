## Терминология

### Линейная регрессия

Задачей линейной регрессии является нахождение коэффициентов уравнения

```
y = kx + b
```
где k - угол наклона прямой, b - сдвиг по оси y

Исходными данными является набор точек, например:

![График линейной регрессии](../assets/images/linear-regression-example.png)


### Логистическая регрессия

Задачей логистической регрессии является нахождение вероятности некоторого события по значениям множества признаков. В случае одной пары переменных x, y функция зависимости выражается как:

```
         1
y = ------------
     1 + e<sup>-x</sup>
```

Исходными данными является набор точек, например:

![График логистической регрессии](../assets/images/logistic-regression-example.png)

### Полносвязанная нейросеть

![Полносвязанная нейросеть](../assets/images/fully-connected-neural-network.png)

Полносвязанная нейросеть состоит из некоторого набора полностью соединённых слоёв. Каждый полностью соединённый слой представляет собой функцию R(m) => R(n). Где каждое из выходных значений R(n) зависит от каждого из входных значений R(m).

### Слабосвязанная нейросеть

![Слабосвязанная нейросеть](../assets/images/sparsely-connected-neural-network.png)

Слабосвязанная нейросеть представляет собой набор слоёв, в которых входные значения связаны только с некоторыми из выходных значений.

### SVM

Так называемый метод опорных векторов или метод обучения с учителем. Задача классификации состоит в определении к какому классу из, как минимум, двух изначально известных относится данный объект. Если классов всего два («спам / не спам», «давать кредит / не давать кредит», «красное / черное»), то задача называется бинарной классификацией. Если классов несколько — многоклассовая (мультиклассовая) классификация. Также могут иметься образцы каждого класса — объекты, про которые заранее известно к какому классу они принадлежат. Такие задачи называют обучением с учителем, а известные данные называются обучающей выборкой.
